# QNN
## Quantized Neural Network


Traditionally, deep learning uses single precision floating point (float32) data type. Recent researches show that using lower precision say half precision floating point (float16) or even unsigned 8-bit integer (uint8) doesn’t impact the neural network accuracy significantly. Although there are now tonnes of tutorials in using machine learning framework like Tensorflow or Pytorch, there aren’t not many that discuss about how to make neural network run faster. Therefore, I decided to put in some tutorials in this area. 

You don’t need to have prior knowledge in quantization but I do expect you be familiar with Tensorflow and basic of deep neural network. If you found any bug or missing modules that should have been installed, feel free to drop me an email.

In this tutorials I will use Tensorflow 1.10 and Python 3.
